from __future__ import annotations

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langchain.schema import HumanMessage, AIMessage
from dotenv import load_dotenv
from typing import TypedDict, List, Annotated
from langgraph.graph.message import add_messages

load_dotenv()

# LLM ì¤€ë¹„
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)


# ğŸ”¥ LangGraph í‘œì¤€ ë°©ì‹ìœ¼ë¡œ ìƒíƒœ ì •ì˜
class ChatState(TypedDict):
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]


# ğŸ”¥ ì™„ì „íˆ ìˆ˜ì •ëœ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(state: ChatState) -> ChatState:
    print(f"ğŸ” DEBUG - Input state: {state}")

    # ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    messages = state.get("messages", [])

    print(f"ğŸ” DEBUG - Messages count: {len(messages)}")
    print(f"ğŸ” DEBUG - Messages: {messages}")

    # ë¹ˆ ë°°ì—´ ì²´í¬
    if not messages:
        print("âš ï¸ WARNING: No messages found!")
        return {"messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")]}

    try:
        # ğŸ”¥ llm.invoke() ì‚¬ìš© (ìƒˆë¡œìš´ ë°©ì‹)
        response = llm.invoke(messages)
        print(f"âœ… SUCCESS - LLM response: {response.content}")

        # ê¸°ì¡´ ë©”ì‹œì§€ + ìƒˆ ì‘ë‹µ ë°˜í™˜
        return {"messages": [response]}  # add_messagesê°€ ìë™ìœ¼ë¡œ í•©ì³ì¤Œ

    except Exception as e:
        print(f"âŒ ERROR in generate_response: {e}")
        return {"messages": [AIMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")]}


# ì¢…ë£Œ ì¡°ê±´ í•¨ìˆ˜ (ë‹¨ìˆœí™”)
def should_continue(state: ChatState) -> str:
    return END  # í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ê³  ë


# ğŸ”¥ LangGraph êµ¬ì„± (ë” ê°„ë‹¨í•˜ê²Œ)
builder = StateGraph(ChatState)
builder.add_node("chat", generate_response)
builder.set_entry_point("chat")
builder.add_edge("chat", END)  # ë‹¨ìˆœí•œ ì—£ì§€
graph = builder.compile()

# í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì„ íƒì‚¬í•­)
if __name__ == "__main__":
    test_state = {"messages": [HumanMessage(content="ì•ˆë…•!")]}
    print("ğŸ§ª Testing...")
    result = graph.invoke(test_state)
    print(f"âœ… Test result: {result}")