import base64
from typing import TypedDict

from dotenv import load_dotenv
from fastapi import UploadFile
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.constants import END
from langgraph.graph import StateGraph

load_dotenv()

llm = ChatOpenAI(model="gpt-4o", temperature=0)

class ImageAnalysisState(TypedDict):
    image_base64: str
    analysis_result: str

def analyze_image(state: ImageAnalysisState) -> dict:
    print("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ")
    try:
        base64_image = state['image_base64']

        # ğŸ”¥ GPTì—ê²Œ ì›í•˜ëŠ” ì–‘ì‹ìœ¼ë¡œ ë‹µë³€í•˜ë¼ê³  ëª…ë ¹
        prompt = "ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ë³´ë‚¸ ì‚¬ëŒê³¼ ë°›ëŠ” ì‚¬ëŒìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì±„íŒ…ì„ ë¶„ì„í•´ì„œ ì±„íŒ… ë‚´ìš©ì„ ë½‘ì•„ì¤˜"


        messages = [
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
            ])
        ]

        response = llm.invoke(messages)
        print(f"response : {response}")

        return {
            "analysis_result": response.content
        }

    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "analysis_result": f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

builder = StateGraph(ImageAnalysisState)
builder.add_node("analyze", analyze_image)
builder.set_entry_point("analyze")
builder.add_edge("analyze", END)

image_analysis_graph = builder.compile()

async def run_graph(uploadFile: UploadFile) -> dict:
    # 1. UploadFileì„ base64ë¡œ ë³€í™˜
    content = await uploadFile.read()
    base64_image = base64.b64encode(content).decode('utf-8')

    initial_content = ImageAnalysisState(image_base64=base64_image, analysis_result='')

    result = image_analysis_graph.invoke(initial_content)
    return result